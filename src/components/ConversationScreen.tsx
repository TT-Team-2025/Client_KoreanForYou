import { useState, useEffect, useRef } from "react";
import { Button } from "./ui/button";
import { Mic, Languages, PhoneOff } from "lucide-react";
import { ConversationSetup, StartScenarioResponse, Message } from "@/types/scenario";
import { getAudioFileUrl } from "@/api/scenario";
import { useSendVoiceMessage } from "@/hooks/scenarios/useSendVoiceMessage";
import { useSendMessage } from "@/hooks/scenarios/useSendMessage";
import { useEndScenario } from "@/hooks/scenarios/useEndScenario";
import { CONVERSATION_TEXT } from "@/constants/conversation";
import { LoadingOverlay } from "./LoadingOverlay";
import { useUserProfile } from "@/hooks/users/useUserProfile";
import { translateText } from "@/utils/translate";

interface ConversationScreenProps {
  onNavigate: (screen: string) => void;
  setup: ConversationSetup;
  sessionData: StartScenarioResponse | null;
  onComplete?: (learningRecord: any) => void;
}


export function ConversationScreen({ onNavigate, setup, sessionData, onComplete }: ConversationScreenProps) {
  const [isRecording, setIsRecording] = useState(false); // ë…¹ìŒ ì¤‘
  const [isMuted, setIsMuted] = useState(false); // ìŒì†Œê±°
  const [showTranslation, setShowTranslation] = useState(false); // ë²ˆì—­
  const [elapsedTime, setElapsedTime] = useState(0); // íƒ€ì´ë¨¸
  const [isAIResponding, setIsAIResponding] = useState(false); // AI ì‘ë‹µ ëŒ€ê¸° ì¤‘
  const [isSTTProcessing, setIsSTTProcessing] = useState(false); // STT ë³€í™˜ ì¤‘
  const [translatingMessageIds, setTranslatingMessageIds] = useState<Set<number>>(new Set()); // ë²ˆì—­ ì¤‘ì¸ ë©”ì‹œì§€ ID
  const [messages, setMessages] = useState<Message[]>([
    {
      id: 1,
      speaker: "ai",
      text: sessionData?.assistant || "ì•ˆë…•í•˜ì„¸ìš”! ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³¼ê¹Œìš”?",
      translation: "",
      timestamp: new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })
    }
  ]);

  // ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ
  const { data: userProfile } = useUserProfile();

  const messagesEndRef = useRef<HTMLDivElement>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null); // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ TTS ì˜¤ë””ì˜¤
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const { mutate: sendVoice, isPending: isSendingVoice } = useSendVoiceMessage();
  const { mutate: sendMessage, isPending: isSendingMessage } = useSendMessage();
  const { mutate: endScenario, isPending: isEndingScenario } = useEndScenario();

  // Play initial TTS audio
  useEffect(() => {
    if (sessionData?.tts_filename && !isMuted) {
      const audioUrl = getAudioFileUrl(sessionData.tts_filename);
      const audio = new Audio(audioUrl);
      audioRef.current = audio;
      currentAudioRef.current = audio;

      audio.play().catch(error => {
        console.error('TTS ì¬ìƒ ì‹¤íŒ¨:', error);
      });

      audio.onended = () => {
        currentAudioRef.current = null;
      };

      return () => {
        audio.pause();
        audio.src = '';
        currentAudioRef.current = null;
      };
    }
  }, [sessionData, isMuted]);

  // Timer
  useEffect(() => {
    const interval = setInterval(() => {
      setElapsedTime((prev) => prev + 1);
    }, 1000);
    return () => clearInterval(interval);
  }, []);

  // Auto scroll to bottom when new message is added
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages]);

  // ë²ˆì—­ ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œ ì•„ì§ ë²ˆì—­ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ë“¤ì„ ë²ˆì—­
  useEffect(() => {
    if (showTranslation && userProfile?.nationality) {
      messages.forEach(async (message) => {
        // ì´ë¯¸ ë²ˆì—­ì´ ìˆê±°ë‚˜ ë²ˆì—­ ì¤‘ì¸ ë©”ì‹œì§€ëŠ” ìŠ¤í‚µ
        if (message.translation || translatingMessageIds.has(message.id)) {
          return;
        }

        // ë²ˆì—­ ì¤‘ í‘œì‹œ
        setTranslatingMessageIds(prev => new Set(prev).add(message.id));

        try {
          const translated = await translateText(message.text, userProfile.nationality!);

          // ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
          setMessages(prev =>
            prev.map(msg =>
              msg.id === message.id
                ? { ...msg, translation: translated }
                : msg
            )
          );
        } catch (error) {
          console.error('ë²ˆì—­ ì‹¤íŒ¨:', error);
        } finally {
          // ë²ˆì—­ ì™„ë£Œ
          setTranslatingMessageIds(prev => {
            const newSet = new Set(prev);
            newSet.delete(message.id);
            return newSet;
          });
        }
      });
    }
  }, [showTranslation, messages, userProfile?.nationality, translatingMessageIds]);

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const handleRecord = async () => {
    if (isMuted || !sessionData) return;

    if (isRecording) {
      // ë…¹ìŒ ì¤‘ì§€
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
    } else {
      // ë…¹ìŒ ì‹œì‘ - í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ëª¨ë“  TTS ì˜¤ë””ì˜¤ ì¤‘ì§€
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current.currentTime = 0;
        currentAudioRef.current = null;
      }

      // ë…¹ìŒ ì‹œì‘
      try {
        // âœ… navigator.mediaDevicesê°€ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome, Edge, Safari ìµœì‹  ë²„ì „ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
          return;
        }

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // ì§€ì›ë˜ëŠ” MIME íƒ€ì… í™•ì¸
        const mimeType = MediaRecorder.isTypeSupported('audio/mp4')
          ? 'audio/mp4'
          : MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
          ? 'audio/webm;codecs=opus'
          : 'audio/webm';

        console.log(CONVERSATION_TEXT.CONSOLE.MIME_TYPE, mimeType);

        const mediaRecorder = new MediaRecorder(stream, { mimeType });
        mediaRecorderRef.current = mediaRecorder;
        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };

        mediaRecorder.onstop = async () => {
          setIsRecording(false);

          const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
          const extension = mimeType.includes('mp4') ? 'mp4' : 'webm';
          const audioFile = new File([audioBlob], `voice.${extension}`, { type: mimeType });

          console.log(CONVERSATION_TEXT.CONSOLE.SENDING_FILE, {
            name: audioFile.name,
            type: audioFile.type,
            size: audioFile.size,
            threadId: sessionData.session_id
          });

          // âœ… ë‚™ê´€ì  ì—…ë°ì´íŠ¸ 1: ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ (ì„ì‹œ í…ìŠ¤íŠ¸)
          const tempUserMessageId = Date.now();
          const tempUserMessage: Message = {
            id: tempUserMessageId,
            speaker: "user",
            text: "ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘...",  // ì„ì‹œ í…ìŠ¤íŠ¸
            translation: "",
            timestamp: new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })
          };
          setMessages(prev => [...prev, tempUserMessage]);

          // 1ë‹¨ê³„: ìŒì„± íŒŒì¼ì„ STTë¡œ ë³€í™˜
          setIsSTTProcessing(true);

          sendVoice(
            {
              thread_id: sessionData.session_id,
              file: audioFile
            },
            {
              onSuccess: (sttData) => {
                // STT ë¡œë”© ì¢…ë£Œ
                setIsSTTProcessing(false);

                // âœ… STT ê²°ê³¼ë¡œ ì„ì‹œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                setMessages(prev =>
                  prev.map(msg =>
                    msg.id === tempUserMessageId
                      ? { ...msg, text: sttData.user_text }  // ì‹¤ì œ STT ê²°ê³¼ë¡œ êµì²´
                      : msg
                  )
                );

                // âœ… ë‚™ê´€ì  ì—…ë°ì´íŠ¸ 2: AI ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ (ì„ì‹œ í…ìŠ¤íŠ¸)
                const tempAIMessageId = Date.now() + 1;
                const tempAIMessage: Message = {
                  id: tempAIMessageId,
                  speaker: "ai",
                  text: "ğŸ’­ ìƒê°í•˜ëŠ” ì¤‘...",  // ì„ì‹œ í…ìŠ¤íŠ¸
                  translation: "",
                  timestamp: new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })
                };
                setMessages(prev => [...prev, tempAIMessage]);

                // AI ì‘ë‹µ ë¡œë”© ì‹œì‘
                setIsAIResponding(true);

                // 2ë‹¨ê³„: STT ê²°ê³¼ë¥¼ AIì—ê²Œ ì „ì†¡í•˜ì—¬ ì‘ë‹µ ë°›ê¸°
                sendMessage(
                  {
                    thread_id: sessionData.session_id,
                    message: sttData.user_text
                  },
                  {
                    onSuccess: (aiData) => {
                      // AI ì‘ë‹µ ë¡œë”© ì¢…ë£Œ
                      setIsAIResponding(false);

                      // âœ… LLM ê²°ê³¼ë¡œ ì„ì‹œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                      setMessages(prev =>
                        prev.map(msg =>
                          msg.id === tempAIMessageId
                            ? { ...msg, text: aiData.assistant }  // ì‹¤ì œ AI ì‘ë‹µìœ¼ë¡œ êµì²´
                            : msg
                        )
                      );

                      // AI ì‘ë‹µ TTS ì¬ìƒ
                      if (aiData.tts_filename && !isMuted) {
                        const audioUrl = getAudioFileUrl(aiData.tts_filename);
                        const audio = new Audio(audioUrl);
                        currentAudioRef.current = audio;

                        audio.play().catch(error => {
                          console.error(CONVERSATION_TEXT.CONSOLE.TTS_PLAY_FAILED, error);
                        });

                        audio.onended = () => {
                          currentAudioRef.current = null;
                        };
                      }
                    },
                    onError: (error) => {
                      setIsAIResponding(false);

                      // âœ… ì—ëŸ¬ ë°œìƒ ì‹œ ì„ì‹œ ë©”ì‹œì§€ ì œê±°
                      setMessages(prev => prev.filter(msg => msg.id !== tempAIMessageId));

                      alert(`AI ì‘ë‹µ ë°›ê¸° ì‹¤íŒ¨: ${error.message}`);
                    }
                  }
                );
              },
              onError: (error) => {
                setIsSTTProcessing(false);
                console.error('STT ì²˜ë¦¬ ì˜¤ë¥˜:', error);

                // âœ… ì—ëŸ¬ ë°œìƒ ì‹œ ì„ì‹œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                setMessages(prev =>
                  prev.map(msg =>
                    msg.id === tempUserMessageId
                      ? { ...msg, text: "âš ï¸ ìŒì„± ì¸ì‹ ì‹¤íŒ¨" }
                      : msg
                  )
                );

                alert('ë‹¤ì‹œ ë…¹ìŒí•´ì£¼ì„¸ìš”');
              }
            }
          );

          // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
          stream.getTracks().forEach(track => track.stop());
        };

        mediaRecorder.start();
        setIsRecording(true);
      } catch (error) {
        console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
        alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      }
    }
  };

  const handleEndConversation = () => {
    if (!sessionData) return;

    // ì‚¬ìš©ì ë°œí™” íšŸìˆ˜ ê³„ì‚° (ì²« AI ë©”ì‹œì§€ ì œì™¸)
    const userMessageCount = messages.filter(msg => msg.speaker === 'user').length;

    // 5ë¬¸ì¥ ë¯¸ë§Œ ë°œí™” ì‹œ í™•ì¸ ë©”ì‹œì§€
    if (userMessageCount < 5) {
      const confirmEnd = window.confirm(
        `í˜„ì¬ ${userMessageCount}ë²ˆ ë°œí™”í•˜ì…¨ìŠµë‹ˆë‹¤.\n5ë²ˆ ì´ìƒ ë°œí™”í•´ì•¼ í•™ìŠµ ê¸°ë¡ì´ ì €ì¥ë©ë‹ˆë‹¤.\n\nê·¸ë˜ë„ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?`
      );
      if (!confirmEnd) return;
    }

    // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ TTS ì™„ì „ ì¢…ë£Œ
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current.currentTime = 0;
      currentAudioRef.current = null;
    }

    // ì‹œë‚˜ë¦¬ì˜¤ ì¢…ë£Œ API í˜¸ì¶œ
    endScenario(
      {
        thread_id: sessionData.session_id
      },
      {
        onSuccess: (data) => {
          console.log('ì‹œë‚˜ë¦¬ì˜¤ ì¢…ë£Œ ì„±ê³µ:', data);

          // AI ëŒ€í™” ì™„ë£Œ ê¸°ë¡ ìƒì„± - ì‹¤ì œ í”¼ë“œë°± ë°ì´í„° í¬í•¨
          const conversationRecord = {
            id: Date.now(),
            type: 'conversation',
            title: setup.topic || 'AI ëŒ€í™” ì—°ìŠµ',
            date: new Date().toISOString().split('T')[0],
            duration: formatTime(data.total_time || elapsedTime),
            score: data.feedback?.detail_comment?.metrics_summary?.overall_score || 0,
            messageCount: data.turn_count || messages.length,
            completionStatus: data.completion_status,
            endTime: data.end_time,
            // ì„œë²„ì—ì„œ ë°›ì€ í”¼ë“œë°± ë°ì´í„° ì „ì²´ í¬í•¨
            feedback: data.feedback,
            threadId: data.thread_id,
            userRole: setup.userRole,
            aiRole: setup.aiRole,
            situation: setup.situation
          };
          console.log('AI ëŒ€í™” ì™„ë£Œ ê¸°ë¡ í™•ì¸ : ', conversationRecord)

          // í•™ìŠµ ê¸°ë¡ì„ ì „ë‹¬í•˜ê³  í”¼ë“œë°±ìœ¼ë¡œ ì´ë™
          if (onComplete) {
            onComplete(conversationRecord);
          }
          onNavigate('feedback');
        },
        onError: (error) => {
          console.error('ì‹œë‚˜ë¦¬ì˜¤ ì¢…ë£Œ ì‹¤íŒ¨:', error);
          alert(`ëŒ€í™” ì¢…ë£Œ ì‹¤íŒ¨: ${error.message}`);
        }
      }
    );
  };

  return (
    <div className="min-h-screen relative flex flex-col" style={{
      background: 'linear-gradient(180deg, #3a3a3c 0%, #2d3561 70%, #3d4578 100%)'
    }}>
      {/* ì¢…ë£Œ ì¤‘ ë¡œë”© ì˜¤ë²„ë ˆì´ */}
      {isEndingScenario && <LoadingOverlay message="ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..." />}

      {/* Header */}
      <header className="flex items-center justify-center px-5 pt-4 pb-4 relative">
        <div className="absolute left-5">
          <Button
            variant="ghost"
            size="icon"
            onClick={() => setShowTranslation(!showTranslation)}
            className={`text-white hover:bg-white/10 ${showTranslation ? 'bg-white/20' : ''}`}
          >
            <Languages className="w-6 h-6" />
          </Button>
        </div>

        <div className="text-white text-lg">{formatTime(elapsedTime)}</div>
      </header>

      {/* Topic & Role Info */}
      <div className="px-6 pb-4 flex-shrink-0">
        <div className="flex justify-center mb-2">
          <div className="inline-flex items-center gap-2 px-4 py-2 rounded-full border border-white/20 bg-white/10">
            <span className="text-white text-sm">{setup.topic}</span>
          </div>
        </div>
        <div className="flex gap-3 justify-center text-xs">
          <div className="text-white/70">
            ë‚˜: <span className="text-white">{setup.userRole}</span>
          </div>
          <div className="text-white/70">
            AI: <span className="text-white">{setup.aiRole}</span>
          </div>
        </div>
      </div>

      {/* Messages Area - Scrollable */}
      <main className="flex-1 overflow-y-auto px-4 pb-4">
        <div className="max-w-2xl mx-auto space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.speaker === 'user' ? 'justify-end' : 'justify-start'}`}
            >
              <div className={`max-w-[80%] ${message.speaker === 'user' ? 'items-end' : 'items-start'} flex flex-col gap-1`}>
                <div
                  className={`px-4 py-3 rounded-2xl ${
                    message.speaker === 'ai'
                      ? 'bg-white/20 text-white'
                      : 'bg-white text-gray-900'
                  }`}
                >
                  <p className="leading-relaxed">{message.text}</p>
                  {showTranslation && (
                    <p className={`text-sm mt-2 pt-2 border-t italic ${
                      message.speaker === 'ai'
                        ? 'border-white/20 text-white/70'
                        : 'border-gray-200 text-gray-600'
                    }`}>
                      {translatingMessageIds.has(message.id) ? (
                        <span className="flex gap-1">
                          ë²ˆì—­ ì¤‘
                          <span className="animate-bounce" style={{ animationDelay: '0ms' }}>.</span>
                          <span className="animate-bounce" style={{ animationDelay: '150ms' }}>.</span>
                          <span className="animate-bounce" style={{ animationDelay: '300ms' }}>.</span>
                        </span>
                      ) : (
                        message.translation || 'ë²ˆì—­ ì¤‘...'
                      )}
                    </p>
                  )}
                </div>
                <span className={`text-xs px-2 ${
                  message.speaker === 'ai' ? 'text-white/50' : 'text-white/50'
                }`}>
                  {message.timestamp}
                </span>
              </div>
            </div>
          ))}

          {/* STT ì²˜ë¦¬ ì¤‘ í‘œì‹œ (ì‚¬ìš©ì ë§í’ì„ ) */}
          {isSTTProcessing && (
            <div className="flex justify-end">
              <div className="max-w-[80%] items-end flex flex-col gap-1">
                <div className="px-4 py-3 rounded-2xl bg-white text-gray-900">
                  <div className="flex gap-1">
                    <span className="animate-bounce" style={{ animationDelay: '0ms' }}>.</span>
                    <span className="animate-bounce" style={{ animationDelay: '150ms' }}>.</span>
                    <span className="animate-bounce" style={{ animationDelay: '300ms' }}>.</span>
                  </div>
                </div>
              </div>
            </div>
          )}

          {/* AI ì‘ë‹µ ë¡œë”© ì¤‘ í‘œì‹œ */}
          {isAIResponding && (
            <div className="flex justify-start">
              <div className="max-w-[80%] items-start flex flex-col gap-1">
                <div className="px-4 py-3 rounded-2xl bg-white/20 text-white">
                  <div className="flex gap-1">
                    <span className="animate-bounce" style={{ animationDelay: '0ms' }}>.</span>
                    <span className="animate-bounce" style={{ animationDelay: '150ms' }}>.</span>
                    <span className="animate-bounce" style={{ animationDelay: '300ms' }}>.</span>
                  </div>
                </div>
              </div>
            </div>
          )}

          <div ref={messagesEndRef} />
        </div>
      </main>

      {/* Bottom Controls */}
      <div className="pb-8 pt-4 flex-shrink-0">
        <div className="flex items-center justify-center gap-8">
          {/* Microphone Button */}
          <Button
            onClick={handleRecord}
            disabled={isMuted || isSendingVoice || isSendingMessage}
            className={`w-16 h-16 rounded-full transition-all ${
              isRecording
                ? 'bg-red-500 hover:bg-red-600 animate-pulse'
                : isSendingVoice || isSendingMessage
                ? 'bg-blue-400 opacity-70'
                : 'bg-white/20 hover:bg-white/30 border-2 border-white'
            }`}
          >
            <Mic className="w-7 h-7 text-white" />
          </Button>

          {/* End Call Button (iPhone style) */}
          <div className="flex flex-col items-center gap-2">
            <Button
              onClick={handleEndConversation}
              disabled={isEndingScenario}
              className={`w-16 h-16 rounded-full transition-all ${
                isEndingScenario
                  ? 'bg-red-400 opacity-70'
                  : 'bg-red-500 hover:bg-red-600'
              }`}
            >
              <PhoneOff className="w-7 h-7 text-white" />
            </Button>
            <span className="text-white/80 text-sm">ì¢…ë£Œ</span>
          </div>

          {/* Mute Button */}
          <Button
            onClick={() => setIsMuted(!isMuted)}
            className={`w-16 h-16 rounded-full transition-all ${
              isMuted
                ? 'bg-red-500/20 border-2 border-red-500'
                : 'bg-white/20 hover:bg-white/30 border-2 border-white'
            }`}
          >
            <span className="text-white text-2xl">{isMuted ? 'ğŸ”‡' : 'ğŸ”Š'}</span>
          </Button>
        </div>
      </div>
    </div>
  );
}
